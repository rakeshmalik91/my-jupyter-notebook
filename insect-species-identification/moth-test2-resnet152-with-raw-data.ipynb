{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45656b90-6763-4104-9aec-e35774545130",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torchviz tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94886411-7ed5-4680-bd18-f19b2393e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"insect-dataset/moth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a97cbc75-ade1-4397-a85f-3b9a1f105aa1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pprint\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69c3dc7-9bc4-4d60-9d44-570fdafe1553",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def split_data_for_train_and_val(data_dir, test_dir, val_dir, train_dir, test_data_weight, val_data_weight, min_file_cnt_for_val):\n",
    "    if os.path.exists(test_dir):\n",
    "        shutil.rmtree(test_dir)\n",
    "    if os.path.exists(val_dir):\n",
    "        shutil.rmtree(val_dir)\n",
    "    if os.path.exists(train_dir):\n",
    "        shutil.rmtree(train_dir)\n",
    "\n",
    "    train_data_cnt = 0\n",
    "    val_data_cnt = 0\n",
    "    test_data_cnt = 0\n",
    "    class_cnt = 0\n",
    "    \n",
    "    for class_dir in Path(data_dir).iterdir():\n",
    "        if class_dir.is_dir() and os.listdir(class_dir):\n",
    "            class_cnt = class_cnt + 1\n",
    "            file_count = sum(1 for file in class_dir.iterdir() if file.is_file())\n",
    "            for file in Path(class_dir).iterdir():\n",
    "                if file.is_file():\n",
    "                    random_float = random.random()\n",
    "                    class_dir_name = class_dir.name\n",
    "                    if file_count >= min_file_cnt_for_val and random_float < test_data_weight:\n",
    "                        target_dir = test_dir\n",
    "                        test_data_cnt = test_data_cnt + 1\n",
    "                    elif file_count >= min_file_cnt_for_val and random_float < test_data_weight + val_data_weight:\n",
    "                        target_dir = val_dir\n",
    "                        val_data_cnt = val_data_cnt + 1\n",
    "                    else:\n",
    "                        target_dir = train_dir\n",
    "                        train_data_cnt = train_data_cnt + 1\n",
    "                    target_dir_path = f\"{target_dir}/{class_dir_name}\"\n",
    "                    if not os.path.exists(target_dir_path):\n",
    "                        os.makedirs(target_dir_path)\n",
    "                    shutil.copy(file, target_dir_path)\n",
    "\n",
    "    print(f\"Class count: {class_cnt}\")\n",
    "    print(f\"Training data count: {train_data_cnt}\")\n",
    "    print(f\"Validation data count: {val_data_cnt}\")\n",
    "    print(f\"Test data count: {test_data_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f61ba5f3-bbb2-494b-ad02-f18dae6bc7ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def init_model_for_training(train_dir, val_dir, batch_size, arch='resnet18'):\n",
    "    transform = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    }\n",
    "    training_datasets = {\n",
    "        'train': datasets.ImageFolder(root=train_dir, transform=transform['train']),\n",
    "        'val': datasets.ImageFolder(root=val_dir, transform=transform['val']),\n",
    "    }\n",
    "    if len(training_datasets['val'].class_to_idx) != len(training_datasets['train'].class_to_idx):\n",
    "        training_datasets['val'].class_to_idx =  training_datasets['train'].class_to_idx\n",
    "        new_val_samples = []\n",
    "        for path, label in training_datasets['val'].samples:\n",
    "            class_name = training_datasets['val'].classes[label]\n",
    "            if class_name in training_datasets['train'].class_to_idx:\n",
    "                new_val_samples.append((path, training_datasets['train'].class_to_idx[class_name]))\n",
    "        training_datasets['val'].samples = new_val_samples\n",
    "        \n",
    "    dataloaders = {\n",
    "        'train': DataLoader(training_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "        'val': DataLoader(training_datasets['val'], batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "    class_names = training_datasets['train'].classes\n",
    "\n",
    "    if arch == 'resnet152':\n",
    "        model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "    elif arch == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    else:\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "    num_classes = len(class_names)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'device': device,\n",
    "        'transform': transform,\n",
    "        'datasets': training_datasets,\n",
    "        'dataloaders': dataloaders,\n",
    "        'class_names': class_names,\n",
    "        'num_classes': num_classes,\n",
    "        'num_features': num_features,\n",
    "        'criterion': criterion,\n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "571bb930-7a23-42c4-b484-4d68d2040753",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train(model_data, num_epochs, model_path, phases=['train', 'val']):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {(epoch+1):4} / {num_epochs:4}\", end=' ')\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model_data['model'].train()\n",
    "            else:\n",
    "                model_data['model'].eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in model_data['dataloaders'][phase]:\n",
    "                inputs, labels = inputs.to(model_data['device']), labels.to(model_data['device'])\n",
    "                model_data['optimizer'].zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model_data['model'](inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = model_data['criterion'](outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        model_data['optimizer'].step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "            epoch_loss = running_loss / len(model_data['datasets'][phase])\n",
    "            epoch_acc = running_corrects.double() / len(model_data['datasets'][phase])\n",
    "            print(f\" | {phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\", end=' ')\n",
    "            if phase == 'train':\n",
    "                model_data['scheduler'].step()\n",
    "        print(f\" | Elapsed time: {datetime.timedelta(seconds=(time.time() - start_time))}\")\n",
    "        torch.save(model_data, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95539812-855d-4f01-ae71-5754adee7b05",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model_data):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = model_data['transform']['val'](image).unsqueeze(0).to(model_data['device'])\n",
    "    with torch.no_grad():\n",
    "        outputs = model_data['model'](image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    try:\n",
    "        return model_data['class_names'][preds[0]]\n",
    "    except (Exception):\n",
    "        return None\n",
    "\n",
    "def predict_top_k(image_path, model_data, k):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = model_data['transform']['val'](image).unsqueeze(0).to(model_data['device'])\n",
    "    with torch.no_grad():\n",
    "        outputs = model_data['model'](image)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, k)\n",
    "    try:\n",
    "        return {model_data['class_names'][top_indices[0][i]]: top_probs[0][i].item() for i in range(0, k)}\n",
    "    except (Exception):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9691c4a4-4d70-4460-9566-b9fca9632e30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def validate_prediction_in_dir(test_dir, model_data):\n",
    "    total = 0\n",
    "    success = 0\n",
    "    failures = {}\n",
    "    for species_dir in Path(test_dir).iterdir():\n",
    "        if species_dir.is_dir():\n",
    "            for file in Path(f\"{species_dir}\").iterdir():\n",
    "                if file.is_file():\n",
    "                    species = file.parts[-2]\n",
    "                    prediction = predict(file, model_data)\n",
    "                    is_success = (species==prediction)\n",
    "                    if not is_success:\n",
    "                        failures[species] = prediction\n",
    "                    total = total + 1\n",
    "                    if is_success:\n",
    "                        success = success + 1\n",
    "    return {\n",
    "        'total': total, \n",
    "        'success': success,\n",
    "        'failures': failures\n",
    "    }\n",
    "\n",
    "def test(model_data, test_dir, print_failures=True):\n",
    "    model_data['model'].eval()\n",
    "    start_time = time.time()\n",
    "    prediction = validate_prediction_in_dir(test_dir, model_data)\n",
    "    print(f\"Accuracy: {prediction['success']} / {prediction['total']} -> {100*prediction['success']/prediction['total']:.2f}%\")\n",
    "    print(f\"Elapsed time: {datetime.timedelta(seconds=(time.time() - start_time))}\")\n",
    "    if print_failures:\n",
    "        print(\"-\"*10)\n",
    "        print(\"Failures:\")\n",
    "        pprint.pprint(prediction['failures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4c78d38-b748-408e-b1e9-5552d3ec0a35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_top_k(model_data, test_dir, k, print_preds=True, print_accuracy=True):\n",
    "    model_data['model'].eval()\n",
    "    top1_success_cnt = 0\n",
    "    success_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for file in Path(test_dir).iterdir():\n",
    "        if print_preds:\n",
    "            print(f\"{file.name.split('.')[0]:25}:\", end=' ')\n",
    "        total_cnt = total_cnt + 1\n",
    "        probs = predict_top_k(file, model_data, k)\n",
    "        for pred, prob in probs.items():\n",
    "            if pred in file.name:\n",
    "                success_cnt = success_cnt + 1\n",
    "            if print_preds:\n",
    "                print(f\"{pred}({prob:.3f}) \", end=' ')\n",
    "        if [pred for pred, prob in probs.items()][0] in file.name:\n",
    "            top1_success_cnt = top1_success_cnt + 1\n",
    "        if print_preds:\n",
    "            print()\n",
    "    if print_accuracy:\n",
    "        if print_preds:\n",
    "            print(\"-\"*10)\n",
    "        print(f\"Top {k} accuracy: {success_cnt} / {total_cnt} -> {success_cnt/total_cnt:.3f}\")\n",
    "        print(f\"Top 1 accuracy: {top1_success_cnt} / {total_cnt} -> {top1_success_cnt/total_cnt:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9147eaca-6e4c-41ab-ba03-1234b4039a43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_proto_dataset(data_dir, proto_data_dir, limit):\n",
    "    file_cnt = 0\n",
    "    for class_dir in Path(data_dir).iterdir():\n",
    "        if class_dir.is_dir() and os.listdir(class_dir):\n",
    "            file_count = sum(1 for file in class_dir.iterdir() if file.is_file())\n",
    "            class_dir_name = class_dir.name\n",
    "            for file in Path(class_dir).iterdir():\n",
    "                if file.is_file():\n",
    "                    target_dir_path = f\"{proto_data_dir}/{class_dir_name}\"\n",
    "                    if not os.path.exists(target_dir_path):\n",
    "                        os.makedirs(target_dir_path)\n",
    "                    shutil.copy(file, target_dir_path)\n",
    "                    file_cnt = file_cnt + 1\n",
    "                    if(file_cnt >= limit):\n",
    "                        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6fae02e3-c6f5-4239-ab8c-adb0ff4bbf7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_retraining(model_data, train_dir, val_dir, batch_size):\n",
    "    model_data['transform'] = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    model_data['datasets'] = {\n",
    "        'train': datasets.ImageFolder(root=train_dir, transform=model_data['transform']['train']),\n",
    "        'val': datasets.ImageFolder(root=val_dir, transform=model_data['transform']['val']),\n",
    "    }\n",
    "    if len(model_data['datasets']['val'].class_to_idx) != len(model_data['datasets']['train'].class_to_idx):\n",
    "        model_data['datasets']['val'].class_to_idx =  model_data['datasets']['train'].class_to_idx\n",
    "        new_val_samples = []\n",
    "        for path, label in model_data['datasets']['val'].samples:\n",
    "            class_name = model_data['datasets']['val'].classes[label]\n",
    "            if class_name in model_data['datasets']['train'].class_to_idx:\n",
    "                new_val_samples.append((path, model_data['datasets']['train'].class_to_idx[class_name]))\n",
    "        model_data['datasets']['val'].samples = new_val_samples\n",
    "        \n",
    "    model_data['dataloaders'] = {\n",
    "        'train': DataLoader(model_data['datasets']['train'], batch_size=batch_size, shuffle=True),\n",
    "        'val': DataLoader(model_data['datasets']['val'], batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "    \n",
    "    for class_name in model_data['datasets']['train'].classes:\n",
    "        if class_name not in model_data['class_names']:\n",
    "            model_data['class_names'].append(class_name)\n",
    "    old_num_classes = model_data['num_classes']\n",
    "    model_data['num_classes'] = len(model_data['class_names'])\n",
    "    \n",
    "    old_fc_weights = model_data['model'].fc.weight.data[:old_num_classes]\n",
    "    model_data['model'].fc = nn.Linear(model_data['num_features'], model_data['num_classes'])\n",
    "    model_data['model'].fc.weight.data[:old_num_classes] = old_fc_weights\n",
    "    \n",
    "    model_data['device'] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_data['model'] = model_data['model'].to(model_data['device'])\n",
    "    \n",
    "    return model_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90936634-1292-410a-89d5-dcd4686eb7fe",
   "metadata": {},
   "source": [
    "# Extract small dataset and train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66eb65d-8531-4792-bb87-c4a53ad00764",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_proto_dataset(f\"{dataset_dir}/data\", f\"{dataset_dir}/proto/data\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d676cb6-2016-43a2-97e8-4d06fabae302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count: 335\n",
      "Training data count: 3586\n",
      "Validation data count: 941\n",
      "Test data count: 473\n"
     ]
    }
   ],
   "source": [
    "split_data_for_train_and_val(f\"{dataset_dir}/proto/data\", f\"{dataset_dir}/proto/test\", f\"{dataset_dir}/proto/val\", f\"{dataset_dir}/proto/train\", 0.1, 0.2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9d2812-4e96-4f3a-8ad5-3a3a5c094eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "num_classes: 335\n",
      "num_features: 2048\n"
     ]
    }
   ],
   "source": [
    "model_data = init_model_for_training(f'{dataset_dir}/proto/train', f'{dataset_dir}/proto/val', 32, 'resnet152')\n",
    "print(f\"device: {model_data['device']}\")\n",
    "print(f\"num_classes: {model_data['num_classes']}\")\n",
    "print(f\"num_features: {model_data['num_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154a7b7-75f9-4f07-abd8-d341f619d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model_data, 25, f\"{dataset_dir}/proto/checkpoint_latest.pth\")\n",
    "shutil.copy(f\"{dataset_dir}/proto/checkpoint_latest.pth\", f\"{dataset_dir}/proto/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed049342-b5f9-491a-8511-d9e764d01169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(f\"{dataset_dir}/proto/checkpoint_latest.pth\", f\"{dataset_dir}/proto/test\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4bd81-83f3-4845-8347-ff7df83106f1",
   "metadata": {},
   "source": [
    "# Try full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59874f59-20e5-469b-b3f3-53e3f1b2a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class count: 3051\n",
      "Training data count: 31622\n",
      "Validation data count: 8466\n",
      "Test data count: 4237\n"
     ]
    }
   ],
   "source": [
    "split_data_for_train_and_val(f\"{dataset_dir}/data\", f\"{dataset_dir}/full/test\", f\"{dataset_dir}/full/val\", f\"{dataset_dir}/full/train\", 0.1, 0.2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18357a91-ae8f-45a4-b864-3745616f2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "num_classes: 3047\n",
      "num_features: 2048\n"
     ]
    }
   ],
   "source": [
    "model_data = init_model_for_training(f'{dataset_dir}/full/train', f'{dataset_dir}/full/val', 32, 'resnet152')\n",
    "print(f\"device: {model_data['device']}\")\n",
    "print(f\"num_classes: {model_data['num_classes']}\")\n",
    "print(f\"num_features: {model_data['num_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fd3b3-a622-4c16-8fc3-0493af4a55bb",
   "metadata": {},
   "source": [
    "### Train 2 epochs with 70% train, 20% val, 10% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a8e529-15e6-473b-9879-12c089629b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 /    2  | Train Loss: 7.0484 Acc: 0.0277  | Val Loss: 11.1510 Acc: 0.0004  | Elapsed time: 0:13:02.099367\n",
      "Epoch    2 /    2  | Train Loss: 5.6067 Acc: 0.0975  | Val Loss: 13.5868 Acc: 0.0000  | Elapsed time: 0:22:24.161010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insect-dataset/moth/full/checkpoint_1737977932.pth'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model_data, 2, f\"{dataset_dir}/full/checkpoint_latest.pth\")\n",
    "shutil.copy(f\"{dataset_dir}/full/checkpoint_latest.pth\", f\"{dataset_dir}/full/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50c3e3e3-1e26-4c43-a960-64058be84e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 529 / 4237 -> 12.49%\n",
      "Elapsed time: 0:02:16.021992\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/test\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c995cf-5288-4f74-96c3-baf6ba36c257",
   "metadata": {},
   "source": [
    "#### Load & verify file saved properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "697ead25-2b88-4483-b098-e3ca61b166f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load(f\"{dataset_dir}/full/checkpoint_latest.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e1668be-76af-47b1-8503-fc50e3d04fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 529 / 4237 -> 12.49%\n",
      "Elapsed time: 0:02:11.483563\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/test\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44530e8-693a-4aba-ae9c-6a5da93e4b9a",
   "metadata": {},
   "source": [
    "### Train 8 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ec30c05-0f28-40cc-a6db-4615f85ee629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 /    8  | Train Loss: 4.3428 Acc: 0.2076  | Val Loss: 17.1842 Acc: 0.0000  | Elapsed time: 0:09:12.678239\n",
      "Epoch    2 /    8  | Train Loss: 3.1974 Acc: 0.3325  | Val Loss: 19.7847 Acc: 0.0000  | Elapsed time: 0:18:26.308181\n",
      "Epoch    3 /    8  | Train Loss: 2.3313 Acc: 0.4657  | Val Loss: 22.8052 Acc: 0.0001  | Elapsed time: 0:27:44.034766\n",
      "Epoch    4 /    8  | Train Loss: 1.7133 Acc: 0.5855  | Val Loss: 25.9527 Acc: 0.0000  | Elapsed time: 0:36:55.719091\n",
      "Epoch    5 /    8  | Train Loss: 1.2721 Acc: 0.6771  | Val Loss: 27.9397 Acc: 0.0001  | Elapsed time: 0:46:16.316828\n",
      "Epoch    6 /    8  | Train Loss: 0.6752 Acc: 0.8315  | Val Loss: 29.9066 Acc: 0.0000  | Elapsed time: 0:55:28.904590\n",
      "Epoch    7 /    8  | Train Loss: 0.5179 Acc: 0.8727  | Val Loss: 31.0145 Acc: 0.0000  | Elapsed time: 1:04:42.652712\n",
      "Epoch    8 /    8  | Train Loss: 0.4426 Acc: 0.8921  | Val Loss: 31.9842 Acc: 0.0000  | Elapsed time: 1:14:02.674499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insect-dataset/moth/full/checkpoint_1737984137.pth'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model_data, 8, f\"{dataset_dir}/full/checkpoint_latest.pth\")\n",
    "shutil.copy(f\"{dataset_dir}/full/checkpoint_latest.pth\", f\"{dataset_dir}/full/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d17064b1-d486-424f-8028-9839ec24eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 2397 / 4237 -> 56.57%\n",
      "Elapsed time: 0:02:09.862823\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/test\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84cf6dca-acd0-4faf-a759-ee4c0c564abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4727 / 8466 -> 55.84%\n",
      "Elapsed time: 0:04:13.736466\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/val\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e778042-f539-4356-a3a5-b70150f4bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artena-dotata-2          : artena-dotata(0.856)  nephele-hespera(0.073)  mocis-frugalis(0.021)  helicoverpa-armigera(0.019)  \n",
      "artena-dotata            : artena-dotata(0.854)  carea-angulata(0.055)  simplicia-schaldusalis(0.039)  ampelophaga-rubiginosa(0.022)  \n",
      "artena-submira-2         : poaphilini-genera-spp(0.561)  acosmeryx-shervillii(0.145)  achaea-janata(0.073)  mocis-undata(0.052)  \n",
      "artena-submira           : artena-dotata(0.389)  artena-submira(0.217)  thyas-coronata(0.118)  oporophylla-ustulata(0.077)  \n",
      "clanis-phalaris-2        : theretra-alecto(0.183)  rhagastis-castanea(0.154)  clanis-titan(0.107)  hippotion-rafflesii(0.105)  \n",
      "clanis-phalaris          : hippotion-rosetta(0.677)  theretra-alecto(0.124)  theretra-clotho(0.093)  palirisa-cervina(0.023)  \n",
      "clanis-undulosa          : theretra-alecto(0.741)  clanis-titan(0.104)  theretra-nessus(0.050)  theretra-clotho(0.036)  \n",
      "conogethes-sahyadriensis : conogethes-spp(0.664)  herpetogramma-cynaralis(0.192)  conogethes-punctiferalis(0.074)  pycnarmon-cribrata(0.021)  \n",
      "dysphania-percota        : dysphania-percota(0.735)  macroglossum-gyrans(0.040)  digama-marchalii(0.035)  lymantria-mathura(0.035)  \n",
      "hemichloridia-euprepia   : procridinae-genera-spp(0.560)  agathia-laetata(0.158)  cephonodes-hylas(0.129)  geometrinae-genera-spp(0.034)  \n",
      "ilema-chloroptera        : ilema-chloroptera(0.706)  spilarctia-spp(0.126)  antheraea-paphia(0.069)  asota-caricae(0.019)  \n",
      "mocis-undata             : mocis-undata(1.000)  mocis-frugalis(0.000)  thyas-coronata(0.000)  hypospila-bolinoides(0.000)  \n",
      "omiza-miliaria-2         : trabala-vishnou(0.951)  eupterote-spp(0.023)  trabala-spp(0.007)  eumelea-ludovicata(0.004)  \n",
      "omiza-miliaria           : oreta-extensa(0.822)  eupterote-spp(0.047)  garaeus-apicata(0.028)  eupterote-undata(0.026)  \n",
      "pseudojana-incandescens  : artena-submira(0.531)  ganisa-spp(0.057)  oglasa-hypenoides(0.041)  marumba-dyras(0.036)  \n",
      "pycnarmon-cribrata       : conogethes-punctiferalis(0.501)  trabala-vishnou(0.100)  perina-nuda(0.097)  asura-miltochrista-group-spp(0.046)  \n",
      "samia-canningii          : samia-canningii(0.881)  attacus-taprobanis(0.098)  samia-cynthia(0.012)  agathodes-ostentalis(0.003)  \n",
      "samia-cynthia            : samia-canningii(0.753)  samia-cynthia(0.231)  attacus-taprobanis(0.009)  antheraea-paphia(0.005)  \n",
      "somatina-rosacea         : somatina-rosacea(0.990)  eublemma-roseonivea(0.005)  habrosyne-spp(0.002)  hypopyra-spp(0.000)  \n",
      "theretra-alecto          : deilephila-rivularis(0.518)  theretra-pallicosta(0.241)  theretra-suffusa(0.058)  theretra-alecto(0.057)  \n",
      "trabala-vishnou          : trabala-spp(0.470)  trabala-vishnou(0.420)  eupterote-spp(0.077)  crinocraspeda-torrida(0.012)  \n",
      "unidentified             : miaromima-cornucopia(0.211)  orudiza-protheclaria(0.196)  mocis-frugalis(0.143)  calyptra-spp(0.085)  \n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7495443-0091-4e88-9e41-a5475578f80d",
   "metadata": {},
   "source": [
    "### Train 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "686dca41-5e12-4f26-af52-24a900a7b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 /   15  | Train Loss: 0.3784 Acc: 0.9077  | Val Loss: 32.3950 Acc: 0.0000  | Elapsed time: 0:09:29.600801\n",
      "Epoch    2 /   15  | Train Loss: 0.3337 Acc: 0.9187  | Val Loss: 33.3562 Acc: 0.0000  | Elapsed time: 0:19:06.111443\n",
      "Epoch    3 /   15  | Train Loss: 0.2815 Acc: 0.9333  | Val Loss: 33.4328 Acc: 0.0000  | Elapsed time: 0:28:21.974020\n",
      "Epoch    4 /   15  | Train Loss: 0.2407 Acc: 0.9458  | Val Loss: 34.6437 Acc: 0.0000  | Elapsed time: 0:37:35.404415\n",
      "Epoch    5 /   15  | Train Loss: 0.1888 Acc: 0.9616  | Val Loss: 34.2778 Acc: 0.0000  | Elapsed time: 0:46:47.961458\n",
      "Epoch    6 /   15  | Train Loss: 0.1789 Acc: 0.9636  | Val Loss: 34.9573 Acc: 0.0000  | Elapsed time: 0:56:01.920862\n",
      "Epoch    7 /   15  | Train Loss: 0.1710 Acc: 0.9667  | Val Loss: 34.7931 Acc: 0.0000  | Elapsed time: 1:05:14.638715\n",
      "Epoch    8 /   15  | Train Loss: 0.1644 Acc: 0.9684  | Val Loss: 34.6984 Acc: 0.0000  | Elapsed time: 1:14:26.601579\n",
      "Epoch    9 /   15  | Train Loss: 0.1603 Acc: 0.9694  | Val Loss: 34.5083 Acc: 0.0000  | Elapsed time: 1:23:37.934361\n",
      "Epoch   10 /   15  | Train Loss: 0.1566 Acc: 0.9697  | Val Loss: 34.8588 Acc: 0.0000  | Elapsed time: 1:32:49.428951\n",
      "Epoch   11 /   15  | Train Loss: 0.1514 Acc: 0.9713  | Val Loss: 35.3050 Acc: 0.0000  | Elapsed time: 1:42:03.856871\n",
      "Epoch   12 /   15  | Train Loss: 0.1464 Acc: 0.9718  | Val Loss: 35.0063 Acc: 0.0000  | Elapsed time: 1:51:15.826731\n",
      "Epoch   13 /   15  | Train Loss: 0.1438 Acc: 0.9740  | Val Loss: 35.2742 Acc: 0.0000  | Elapsed time: 2:00:25.917244\n",
      "Epoch   14 /   15  | Train Loss: 0.1442 Acc: 0.9741  | Val Loss: 35.0891 Acc: 0.0000  | Elapsed time: 2:09:40.301059\n",
      "Epoch   15 /   15  | Train Loss: 0.1458 Acc: 0.9742  | Val Loss: 34.9859 Acc: 0.0000  | Elapsed time: 2:18:51.664563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insect-dataset/moth/full/checkpoint_1737992855.pth'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model_data, 15, f\"{dataset_dir}/full/checkpoint_latest.pth\")\n",
    "shutil.copy(f\"{dataset_dir}/full/checkpoint_latest.pth\", f\"{dataset_dir}/full/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79fcb0f3-234d-4a4a-94df-66da3d67d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 2473 / 4237 -> 58.37%\n",
      "Elapsed time: 0:02:14.230098\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/test\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30b97619-bcc2-40c5-8c17-218da87ed6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 6006 / 8466 -> 70.94%\n",
      "Elapsed time: 0:04:01.650916\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/val\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f16e12be-ad8c-4b0e-b1d0-494cb67db522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22947 / 31622 -> 72.57%\n",
      "Elapsed time: 0:15:46.898181\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/train\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d563c36f-3c08-48d6-a515-e3eedb135e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artena-dotata-2          : artena-dotata(0.752)  simplicia-spp(0.038)  nephele-hespera(0.032)  achaea-serva(0.024)  \n",
      "artena-dotata            : artena-dotata(0.566)  sympis-rufibasis(0.047)  Odontopera-spp(0.045)  odontopera-bilinearia(0.043)  \n",
      "artena-submira-2         : artena-submira(0.522)  pseudojana-incandescens(0.072)  calyptra-spp(0.056)  lebeda-nobilis(0.029)  \n",
      "artena-submira           : artena-dotata(0.443)  artena-submira(0.138)  poaphilini-genera-spp(0.035)  lyssa-zampa(0.034)  \n",
      "clanis-phalaris-2        : theretra-alecto(0.502)  theretra-clotho(0.065)  marumba-cristata(0.052)  clanis-titan(0.037)  \n",
      "clanis-phalaris          : hippotion-rosetta(0.238)  theretra-alecto(0.202)  theretra-pallicosta(0.148)  theretra-clotho(0.072)  \n",
      "clanis-undulosa          : clanis-titan(0.527)  marumba-cristata(0.132)  clanis-undulosa(0.099)  theretra-alecto(0.038)  \n",
      "conogethes-sahyadriensis : conogethes-spp(0.352)  conogethes-punctiferalis(0.227)  psyra-cuneata(0.209)  pycnarmon-cribrata(0.065)  \n",
      "dysphania-percota        : lymantria-mathura(0.207)  dysphania-percota(0.136)  lymantria-spp(0.118)  lymantria-grandis(0.110)  \n",
      "hemichloridia-euprepia   : sauris-spp(0.217)  tyana-pustulifera(0.099)  psilogramma-vates(0.081)  angonyx-krishna(0.054)  \n",
      "ilema-chloroptera        : ilema-chloroptera(0.940)  miltochrista-discisigna(0.018)  dysphania-militaris(0.011)  eudocima-hypermnestra(0.010)  \n",
      "mocis-undata             : mocis-undata(0.978)  gesonia-spp(0.004)  thyas-coronata(0.004)  dierna-patibulum(0.003)  \n",
      "omiza-miliaria-2         : trabala-vishnou(0.839)  hyperythra-lutea(0.026)  sinobirma-myanmarensis(0.019)  crinocraspeda-torrida(0.018)  \n",
      "omiza-miliaria           : eupterote-spp(0.409)  cricula-trifenestrata(0.208)  thyas-coronata(0.058)  hamodes-propitia(0.044)  \n",
      "pseudojana-incandescens  : artena-submira(0.206)  heterothera-spp(0.204)  dierna-strigata(0.185)  simplicia-schaldusalis(0.076)  \n",
      "pycnarmon-cribrata       : trabala-vishnou(0.548)  asura-miltochrista-group-spp(0.118)  spilarctia-spp(0.048)  ophiusa-tirhaca(0.024)  \n",
      "samia-canningii          : samia-canningii(0.703)  deilephila-rivularis(0.141)  samia-cynthia(0.047)  attacus-atlas(0.022)  \n",
      "samia-cynthia            : samia-canningii(0.846)  samia-cynthia(0.134)  attacus-atlas(0.004)  attacus-taprobanis(0.003)  \n",
      "somatina-rosacea         : somatina-rosacea(0.992)  hypopyra-spp(0.004)  habrosyne-spp(0.001)  westermannia-superba(0.001)  \n",
      "theretra-alecto          : deilephila-rivularis(0.422)  theretra-pallicosta(0.300)  theretra-alecto(0.097)  theretra-nessus(0.029)  \n",
      "trabala-vishnou          : trabala-vishnou(0.820)  trabala-spp(0.092)  eupterote-spp(0.027)  ornithospila-avicularia(0.021)  \n",
      "unidentified             : lyssa-zampa(0.153)  orudiza-protheclaria(0.125)  hemiscopis-suffusalis(0.090)  apona-caschmirensis(0.073)  \n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe0713-dac3-42b2-9d48-7400793a3757",
   "metadata": {},
   "source": [
    "### Train with all 100% data for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "010c282c-4daf-49e4-9b8d-f9739d6d96e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "num_classes: 3051\n",
      "num_features: 2048\n"
     ]
    }
   ],
   "source": [
    "model_data = prepare_for_retraining(model_data, f'{dataset_dir}/data', f'{dataset_dir}/full/val', 32)\n",
    "print(f\"device: {model_data['device']}\")\n",
    "print(f\"num_classes: {model_data['num_classes']}\")\n",
    "print(f\"num_features: {model_data['num_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b278472-7575-40c8-80d2-811849d8e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 /   10  | Train Loss: 3.5844 Acc: 0.4054  | Elapsed time: 0:10:56.711135\n",
      "Epoch    2 /   10  | Train Loss: 1.1778 Acc: 0.7077  | Elapsed time: 0:21:58.167607\n",
      "Epoch    3 /   10  | Train Loss: 0.6566 Acc: 0.8163  | Elapsed time: 0:33:00.221350\n",
      "Epoch    4 /   10  | Train Loss: 0.4229 Acc: 0.8757  | Elapsed time: 0:44:02.327792\n",
      "Epoch    5 /   10  | Train Loss: 0.3086 Acc: 0.9091  | Elapsed time: 0:55:04.145452\n",
      "Epoch    6 /   10  | Train Loss: 0.2512 Acc: 0.9236  | Elapsed time: 1:06:06.113104\n",
      "Epoch    7 /   10  | Train Loss: 0.1971 Acc: 0.9400  | Elapsed time: 1:17:08.019445\n",
      "Epoch    8 /   10  | Train Loss: 0.0678 Acc: 0.9820  | Elapsed time: 1:28:10.299961\n",
      "Epoch    9 /   10  | Train Loss: 0.0304 Acc: 0.9930  | Elapsed time: 1:39:13.228200\n",
      "Epoch   10 /   10  | Train Loss: 0.0215 Acc: 0.9951  | Elapsed time: 1:50:15.626157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insect-dataset/moth/full/checkpoint_1738002319.pth'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model_data, 10, f\"{dataset_dir}/full/checkpoint_latest.pth\", phases=['train'])\n",
    "shutil.copy(f\"{dataset_dir}/full/checkpoint_latest.pth\", f\"{dataset_dir}/full/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f1ea756-b846-4bba-b9e5-a02ff013abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4231 / 4237 -> 99.86%\n",
      "Elapsed time: 0:02:09.365678\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/test\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac4053c3-08d7-4002-b232-a0dd9eb9f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8456 / 8466 -> 99.88%\n",
      "Elapsed time: 0:04:09.827129\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/val\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f37e95b-e019-4526-91d4-299c58c99210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31577 / 31622 -> 99.86%\n",
      "Elapsed time: 0:15:26.177914\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/full/train\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2fd61-ed59-4fc8-8c00-9b7832d4c6aa",
   "metadata": {},
   "source": [
    "#### All data have been trained on. only \"my-test\" has unseen data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01e07b52-bfdc-4349-8a66-19f604075c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artena-dotata-2          : artena-dotata(1.000)  artena-submira(0.000)  achaea-serva(0.000)  clanidopsis-exusta(0.000)  \n",
      "artena-dotata            : artena-dotata(1.000)  bastilla-praetermissa(0.000)  bastilla-crameri(0.000)  artena-submira(0.000)  \n",
      "artena-submira-2         : artena-submira(0.633)  poaphilini-genera-spp(0.189)  mocis-undata(0.070)  thyas-coronata(0.030)  \n",
      "artena-submira           : artena-dotata(0.499)  artena-submira(0.275)  thyas-coronata(0.122)  episparis-tortuosalis(0.055)  \n",
      "clanis-phalaris-2        : clanis-phalaris(0.564)  acosmeryx-pseudonaga(0.200)  marumba-irata(0.139)  clanidopsis-exusta(0.042)  \n",
      "clanis-phalaris          : theretra-clotho(0.722)  clanis-bilineata(0.168)  clanis-phalaris(0.029)  theretra-pallicosta(0.024)  \n",
      "clanis-undulosa          : clanis-titan(0.387)  clanis-undulosa(0.338)  ambulyx-belli(0.147)  theretra-alecto(0.040)  \n",
      "conogethes-sahyadriensis : conogethes-spp(0.673)  argina-astrea(0.279)  conogethes-punctiferalis(0.018)  pycnarmon-cribrata(0.017)  \n",
      "hemichloridia-euprepia   : hemichloridia-euprepia(0.659)  angonyx-krishna(0.249)  macroglossum-bombylans(0.036)  nephele-hespera(0.031)  \n",
      "ilema-chloroptera        : ilema-chloroptera(1.000)  eudocima-materna(0.000)  thyas-coronata(0.000)  eudocima-homaena(0.000)  \n",
      "mocis-undata             : mocis-undata(1.000)  mocis-discios(0.000)  thyas-coronata(0.000)  petelia-spp(0.000)  \n",
      "omiza-miliaria-2         : trabala-vishnou(0.873)  hyperythra-lutea(0.099)  hypochrosis-flavifusata(0.014)  antheua-servula(0.006)  \n",
      "omiza-miliaria           : hypopyra-spp(0.723)  decetia-subobscurata(0.046)  oreta-suffusa(0.038)  cricula-trifenestrata(0.034)  \n",
      "pseudojana-incandescens  : pseudojana-incandescens(0.739)  ganisa-spp(0.163)  artena-submira(0.076)  eupterote-spp(0.018)  \n",
      "pycnarmon-cribrata       : asura-miltochrista-group-spp(0.969)  trabala-vishnou(0.011)  olene-mendosa(0.009)  psilochira-lineata(0.008)  \n",
      "samia-canningii          : samia-canningii(0.992)  samia-cynthia(0.008)  attacus-taprobanis(0.000)  agathodes-ostentalis(0.000)  \n",
      "samia-cynthia            : samia-canningii(0.957)  samia-cynthia(0.042)  attacus-taprobanis(0.000)  antheraea-paphia(0.000)  \n",
      "somatina-rosacea         : somatina-rosacea(1.000)  eublemma-roseonivea(0.000)  hypopyra-spp(0.000)  eublemma-amabilis(0.000)  \n",
      "theretra-alecto          : theretra-alecto(0.941)  hippotion-rosetta(0.024)  deilephila-rivularis(0.015)  theretra-clotho(0.011)  \n",
      "trabala-vishnou          : trabala-spp(0.635)  trabala-vishnou(0.363)  comibaena-spp(0.002)  crinocraspeda-torrida(0.000)  \n",
      "__dysphania-percota      : dysphania-percota(1.000)  achaea-janata(0.000)  zeuzerini-genera-spp(0.000)  lymantria-detersa(0.000)  \n",
      "__eupterote-undata       : noreia-ajaia(0.516)  albara-reversaria(0.183)  thosea-spp(0.102)  eupterote-pandya(0.074)  \n",
      "----------\n",
      "Top 4 accuracy: 17 / 22 -> 0.773\n",
      "Top 1 accuracy: 12 / 22 -> 0.545\n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d3b1424-e9a8-4ff6-a439-0811bf04bad3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 accuracy: 19 / 22 -> 0.864\n",
      "Top 1 accuracy: 12 / 22 -> 0.545\n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 10, print_preds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b9787-32e8-4b2d-94a2-22d1ca626a2a",
   "metadata": {},
   "source": [
    "### Train 15 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c5a15d9-c7f3-4986-8972-de39f79cad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load(f\"{dataset_dir}/full/checkpoint.resnet152.2025.01.28.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22e812b5-a6ae-4fa7-a5ae-d5cc44c569c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "num_classes: 3051\n",
      "num_features: 2048\n"
     ]
    }
   ],
   "source": [
    "model_data = prepare_for_retraining(model_data, f'{dataset_dir}/data', f'{dataset_dir}/full/val', 32)\n",
    "print(f\"device: {model_data['device']}\")\n",
    "print(f\"num_classes: {model_data['num_classes']}\")\n",
    "print(f\"num_features: {model_data['num_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed239a27-bb93-4926-ac94-5ff8b5106739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 /   15  | Train Loss: 0.0171 Acc: 0.9960  | Elapsed time: 0:10:36.996702\n",
      "Epoch    2 /   15  | Train Loss: 0.0150 Acc: 0.9965  | Elapsed time: 0:21:21.279913\n",
      "Epoch    3 /   15  | Train Loss: 0.0120 Acc: 0.9973  | Elapsed time: 0:32:23.928651\n",
      "Epoch    4 /   15  | Train Loss: 0.0112 Acc: 0.9975  | Elapsed time: 0:43:16.842611\n",
      "Epoch    5 /   15  | Train Loss: 0.0072 Acc: 0.9987  | Elapsed time: 0:54:10.058172\n",
      "Epoch    6 /   15  | Train Loss: 0.0071 Acc: 0.9986  | Elapsed time: 1:05:04.588430\n",
      "Epoch    7 /   15  | Train Loss: 0.0064 Acc: 0.9986  | Elapsed time: 1:16:00.932254\n",
      "Epoch    8 /   15  | Train Loss: 0.0060 Acc: 0.9988  | Elapsed time: 1:26:53.555932\n",
      "Epoch    9 /   15  | Train Loss: 0.0054 Acc: 0.9990  | Elapsed time: 1:37:44.153952\n",
      "Epoch   10 /   15  | Train Loss: 0.0049 Acc: 0.9991  | Elapsed time: 1:48:35.034925\n",
      "Epoch   11 /   15  | Train Loss: 0.0051 Acc: 0.9989  | Elapsed time: 1:59:25.057349\n",
      "Epoch   12 /   15  | Train Loss: 0.0048 Acc: 0.9991  | Elapsed time: 2:10:13.250712\n",
      "Epoch   13 /   15  | Train Loss: 0.0049 Acc: 0.9991  | Elapsed time: 2:21:03.126884\n",
      "Epoch   14 /   15  | Train Loss: 0.0048 Acc: 0.9991  | Elapsed time: 2:31:56.922887\n",
      "Epoch   15 /   15  | Train Loss: 0.0047 Acc: 0.9991  | Elapsed time: 2:42:56.624722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insect-dataset/moth/full/checkpoint_1738074381.pth'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model_data, 15, f\"{dataset_dir}/full/checkpoint_latest.pth\", phases=['train'])\n",
    "shutil.copy(f\"{dataset_dir}/full/checkpoint_latest.pth\", f\"{dataset_dir}/full/checkpoint_{int(time.time())}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "77391891-7fc8-4f77-8544-43bd01cac5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artena-dotata-2          : artena-dotata(1.000)  simplicia-spp(0.000)  herminiinae-genera-spp(0.000)  achaea-serva(0.000)  \n",
      "artena-dotata            : artena-dotata(1.000)  bastilla-praetermissa(0.000)  simplicia-bimarginata(0.000)  artena-submira(0.000)  \n",
      "artena-submira-2         : artena-submira(0.570)  poaphilini-genera-spp(0.175)  achaea-janata(0.126)  buzara-onelia(0.043)  \n",
      "artena-submira           : artena-submira(0.332)  thyas-coronata(0.320)  artena-dotata(0.263)  episparis-tortuosalis(0.064)  \n",
      "clanis-phalaris-2        : clanis-phalaris(0.963)  acosmeryx-pseudonaga(0.021)  marumba-irata(0.006)  clanidopsis-exusta(0.004)  \n",
      "clanis-phalaris          : theretra-clotho(0.587)  clanis-bilineata(0.335)  hippotion-rosetta(0.016)  theretra-pallicosta(0.015)  \n",
      "clanis-undulosa          : ambulyx-belli(0.478)  clanis-titan(0.356)  clanis-undulosa(0.078)  gangarides-vittipalpis(0.029)  \n",
      "conogethes-sahyadriensis : conogethes-spp(0.982)  argina-astrea(0.012)  conogethes-punctiferalis(0.003)  pycnarmon-cribrata(0.002)  \n",
      "hemichloridia-euprepia   : hemichloridia-euprepia(0.553)  angonyx-krishna(0.209)  macroglossum-bombylans(0.149)  nephele-hespera(0.047)  \n",
      "ilema-chloroptera        : ilema-chloroptera(1.000)  eudocima-materna(0.000)  eudocima-homaena(0.000)  dysphania-militaris(0.000)  \n",
      "mocis-undata             : mocis-undata(1.000)  mocis-discios(0.000)  thyas-coronata(0.000)  petelia-spp(0.000)  \n",
      "omiza-miliaria-2         : trabala-vishnou(0.970)  conogethes-punctiferalis(0.019)  conogethes-sahyadriensis(0.003)  hypochrosis-flavifusata(0.003)  \n",
      "omiza-miliaria           : cricula-trifenestrata(0.322)  hypopyra-spp(0.275)  thyas-honesta(0.087)  oreta-suffusa(0.082)  \n",
      "pseudojana-incandescens  : pseudojana-incandescens(0.920)  artena-submira(0.033)  eupterote-spp(0.027)  ganisa-spp(0.017)  \n",
      "pycnarmon-cribrata       : asura-miltochrista-group-spp(0.981)  olene-mendosa(0.013)  psilochira-lineata(0.003)  trabala-vishnou(0.003)  \n",
      "samia-canningii          : samia-canningii(1.000)  samia-cynthia(0.000)  attacus-taprobanis(0.000)  daphnis-nerii(0.000)  \n",
      "samia-cynthia            : samia-canningii(0.998)  attacus-taprobanis(0.001)  samia-cynthia(0.001)  antheraea-paphia(0.000)  \n",
      "somatina-rosacea         : somatina-rosacea(1.000)  eublemma-roseonivea(0.000)  hypopyra-spp(0.000)  eublemma-amabilis(0.000)  \n",
      "theretra-alecto          : theretra-alecto(0.970)  hippotion-rosetta(0.014)  theretra-clotho(0.006)  deilephila-rivularis(0.004)  \n",
      "trabala-vishnou          : trabala-spp(0.695)  trabala-vishnou(0.290)  comibaena-spp(0.015)  crinocraspeda-torrida(0.000)  \n",
      "__dysphania-percota      : dysphania-percota(1.000)  achaea-janata(0.000)  lymantria-detersa(0.000)  zeuzerini-genera-spp(0.000)  \n",
      "__eupterote-undata       : albara-reversaria(0.472)  thosea-spp(0.225)  eupterote-pandya(0.142)  noreia-ajaia(0.093)  \n",
      "----------\n",
      "Top 4 accuracy: 16 / 22 -> 0.727\n",
      "Top 1 accuracy: 13 / 22 -> 0.591\n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "abc16304-28ec-4f5e-b35d-6844212488d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 accuracy: 17 / 22 -> 0.773\n",
      "Top 1 accuracy: 13 / 22 -> 0.591\n"
     ]
    }
   ],
   "source": [
    "test_top_k(model_data, f\"{dataset_dir}/my-test\", 10, print_preds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6890f048-e652-4e09-8c1f-82b43c7396d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44296 / 44325 -> 99.93%\n",
      "Elapsed time: 0:21:41.783535\n"
     ]
    }
   ],
   "source": [
    "test(model_data, f\"{dataset_dir}/data\", print_failures=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3267c3-4c10-4430-82fc-353cab96d0a6",
   "metadata": {},
   "source": [
    "#### Fixing class_to_idx for val dataset in prepare_for_retraining & init_model_for_training\n",
    "causing to print accuracy as 0% in val phase during train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ec2c956b-c449-4455-b214-f3bdde1b7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "num_classes: 3051\n",
      "num_features: 2048\n",
      "Epoch    1 /    1  | Train Loss: 0.0049 Acc: 0.9990  | Val Loss: 0.0020 Acc: 0.9992  | Elapsed time: 0:11:42.693817\n"
     ]
    }
   ],
   "source": [
    "model_data = torch.load(f\"{dataset_dir}/full/checkpoint_1738074381.pth\", weights_only=False)\n",
    "model_data = prepare_for_retraining(model_data, f'{dataset_dir}/data', f'{dataset_dir}/full/val', 32)\n",
    "print(f\"device: {model_data['device']}\")\n",
    "print(f\"num_classes: {model_data['num_classes']}\")\n",
    "print(f\"num_features: {model_data['num_features']}\")\n",
    "train(model_data, 1, f\"{dataset_dir}/full/checkpoint_latest.pth\", phases=['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f92e8d-20b1-4934-ad10-13ef266e97fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
