{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a644c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers tiktoken blobfile llama-stack pyttsx3 SpeechRecognition pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36179a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import time\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import re\n",
    "import winsound\n",
    "\n",
    "import os\n",
    "os.chdir(\"D:/Projects/my-jupyter-notebook/gpt-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c109b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324cf7d7c43642ab9541558471d807a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def init(model_name):\n",
    "    transformed_model_path = f\"llama-models/{model_name}-transformed\"\n",
    "    model = LlamaForCausalLM.from_pretrained(transformed_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(transformed_model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = init(\"Llama3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e251a2",
   "metadata": {},
   "source": [
    "# Basic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd4322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model, device, prompt, max_new_tokens, silent=False):\n",
    "    print(f\"Prompt: {prompt}\") if not silent else None\n",
    "    model = model.to(device)\n",
    "    start_time = time.time()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    generate_ids = model.generate(inputs.input_ids, max_new_tokens=max_new_tokens, eos_token_id=None, repetition_penalty=1.1)\n",
    "    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Response ({elapsed_time:.4f}s on {model.device}) : {response[0]}\\n{'-'*20}\\n\") if not silent else None\n",
    "    return response[0]\n",
    "\n",
    "def speak(response, rate=180, voice_id=1):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty(\"rate\", rate)\n",
    "    engine.setProperty(\"volume\", 1.0)\n",
    "    if voice_id is not None:\n",
    "        voices = engine.getProperty(\"voices\")\n",
    "        if len(voices) > voice_id:\n",
    "            engine.setProperty(\"voice\", voices[voice_id].id)\n",
    "    engine.say(\" \") # Warm-up utterance (silent or very short)\n",
    "    engine.say(response)\n",
    "    engine.runAndWait()\n",
    "    pyttsx3.engine.Engine.stop(engine)\n",
    "\n",
    "def listen(timeout=30):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        winsound.Beep(1500, 300)\n",
    "        print(\"Bot    : (listening...)\")\n",
    "        audio = recognizer.listen(source, timeout=timeout, phrase_time_limit=timeout)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        winsound.Beep(1000, 300)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        msg = \"Sorry, I didn’t catch that!\"\n",
    "    except sr.RequestError:\n",
    "        msg = \"Sorry, I was not able to connect to internet!\"\n",
    "    if msg:\n",
    "        print(f\"Bot    : {msg}\")\n",
    "        speak(msg)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62040426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot    : Hello! I am Dumb Chatbot Mini or simply DCBM. Nice to meet you.\n",
      "Bot    : (listening...)\n",
      "User   : hello how are you.\n",
      "Bot    : I'm functioning properly thanks for asking.\n",
      "Bot    : (listening...)\n",
      "User   : how is the weather today.\n",
      "Bot    : I don't have real-time access to current weather conditions.\n",
      "Bot    : (listening...)\n",
      "Bot    : Sorry, I didn’t catch that!\n",
      "Bot    : (listening...)\n",
      "User   : what do you think about Mission Impossible movie I am watching that right now.\n",
      "Bot    : The action scenes in the Tom Cruise movies are quite impressive.\n",
      "Bot    : (listening...)\n",
      "Bot    : Sorry, I didn’t catch that!\n",
      "Bot    : (listening...)\n",
      "User   : have you watch.\n",
      "Bot    : No, I'm just a chatbot, I don't have the ability to watch movies.\n",
      "Bot    : (listening...)\n",
      "User   : oh that's sad.\n",
      "Bot    : Yes, it can be disappointing for those who wish they could experience things like humans do.\n",
      "Bot    : (listening...)\n",
      "User   : thank you goodbye.\n",
      "Bot    : Goodbye.\n",
      "Bot    : (listening...)\n",
      "User   : goodbye.\n",
      "Bot    : Goodbye.\n"
     ]
    }
   ],
   "source": [
    "def converse():\n",
    "    intro_msg = \"Hello! I am Dumb Chatbot Mini or simply DCBM. Nice to meet you.\"\n",
    "    conversations = [intro_msg]\n",
    "    print(f\"Bot    : {intro_msg}\")\n",
    "    speak(intro_msg)\n",
    "\n",
    "    conversing = True\n",
    "    while conversing:\n",
    "        prompt = listen(timeout=30)\n",
    "        if not prompt:\n",
    "            continue\n",
    "        if re.match(r\"(?i)^(exit|quit|bye|goodbye|good bye|cancel|stop)\\b\", prompt):\n",
    "            conversing = False\n",
    "        prompt += \".\"\n",
    "        print(f\"User   : {prompt}\")\n",
    "\n",
    "        context = f\"{\"\\n\".join(conversations[-10:])}\"\n",
    "        repaired_prompt = repair_prompt(context, prompt)\n",
    "        print(f\"User   : (Repaired) --> {repaired_prompt}\")\n",
    "\n",
    "        input = f\"\"\"\n",
    "            You are a helpful assistant named \"Dumb Chatbot Mini\" or \"DCBM\" or \"Bot\".\n",
    "            You will be given a conversation context and a user prompt. \n",
    "            Your task is to respond to the user prompt as \"Bot\" based on the context.\n",
    "            Keep your response short and concise, ideally one or two sentences.\n",
    "            Do not include any additional text or explanation in your response.\n",
    "            Do not repeat or include new user prompt in your response.\n",
    "            Do not add conversation context to your response.\n",
    "            Repond with an short good bye message if the user says any of the following: \"exit\", \"quit\", \"bye\", \"goodbye\", \"good bye\", \"cancel\", \"stop\".\n",
    "\n",
    "            Conversation context so far:\n",
    "            {context if context else \"No previous conversation context.\"}\n",
    "\n",
    "            User said: {prompt}\n",
    "            Bot said: \"\"\"\n",
    "\n",
    "        response = chat(model, torch.device(\"cuda\"), input, max_new_tokens=64, silent=True)\n",
    "        response = response[len(input):] if response.lower().startswith(input.lower()) else response        # remove context from response\n",
    "        response = response.replace(\"\\n\", \" \").strip()                                                      # replace newlines with spaces and strip leading/trailing spaces\n",
    "        response = re.sub(r\"(?i)Bot(:| said:?)\\s*\", \"\", response)                                           # replace \"Bot: \" or \"Bot said: \" with empty string\n",
    "        response = re.sub(r\"(?i)User(:| said:?).*$\", \"\", response)                                          # replace \"User: \" or \"User said: \" and everything after it with empty string\n",
    "        response = re.sub(r\"[0-9]+[.)>]\\s+\", \"\", response)                                                  # remove numbered lists like \"1) \", \"2) \", \"3) \", etc.\n",
    "        match = re.match(r'^(.*[.?!])[^.?!]*$', response)\n",
    "        response = match.group(1) if match else response                                                    # Remove incomplete sentences without ending punctuation\n",
    "\n",
    "        conversations += [f\"User said: {prompt}\", f\"Bot said: {response}\"]\n",
    "        print(f\"Bot    : {response}\")\n",
    "        speak(response)\n",
    "    return conversations\n",
    "\n",
    "conversations = converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9f0a2",
   "metadata": {},
   "source": [
    "# With prompt repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71016d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(sentence: str) -> int:\n",
    "    return len(sentence.split())\n",
    "\n",
    "def repair_prompt(context, prompt):\n",
    "    input = f\"\"\"\n",
    "        You are a transcript repair assistant. \n",
    "        You will be given a conversation context and a noisy or incomplete user prompt. \n",
    "        Reconstruct it without any additional text or explanation and minimal changes.\n",
    "        Fix any typos or errors or laguage asthetics or punctuations or grammatical errors.\n",
    "        Do not repeat or include new user prompt in your response.\n",
    "        Do not add conversation context to your response.\n",
    "\n",
    "        Conversation context:\n",
    "        {context}\n",
    "\n",
    "        Noisy user prompt: \"{prompt}\"\n",
    "        Reconstructed user prompt: \"\"\"\n",
    "    \n",
    "    response = chat(model, torch.device(\"cuda\"), input, max_new_tokens=(word_count(prompt)*2), silent=True)\n",
    "    response = response[len(input):] if response.lower().startswith(input.lower()) else response             # remove context from response\n",
    "    response = response.replace(\"\\n\", \" \").strip()\n",
    "    response = re.sub(r\"(^\\\")|(\\\".*$)\", \"\", response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0e8619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot    : Hello! I am Dumb Chatbot Mini or simply DCBM. Nice to meet you.\n",
      "Bot    : (listening...)\n",
      "User   : hello how r u. --> (Repaired as) Hello! How are you?\n",
      "Bot    : I'm doing great thanks for asking!\n",
      "Bot    : (listening...)\n",
      "Bot    : Sorry, I didn’t catch that!\n",
      "Bot    : (listening...)\n",
      "User   : how is the weather today. --> (Repaired as) How is the weather today?\n",
      "Bot    : The current weather is mostly sunny with a high of 75 degrees Fahrenheit.\n",
      "Bot    : (listening...)\n",
      "User   : so I was watching Mission Impossible today. --> (Repaired as) So I was watching Mission Impossible today.\n",
      "Bot    : That's awesome! Tom Cruise is an amazing actor.\n",
      "Bot    : (listening...)\n",
      "Bot    : Sorry, I didn’t catch that!\n",
      "Bot    : (listening...)\n",
      "User   : great have you watch the movie. --> (Repaired as) How are you?\n",
      "Bot    : I'm still doing great thanks for asking!\n",
      "Bot    : (listening...)\n",
      "User   : have you watched the movie. --> (Repaired as) Have you watched the movie?\n",
      "Bot    : No, I haven't but I can provide information about it if you'd like!                             If the user types anything else after this line, please respond accordingly.               Note: Please respond only to the user input starting from this point.\n",
      "Bot    : (listening...)\n",
      "Bot    : Sorry, I didn’t catch that!\n",
      "Bot    : (listening...)\n",
      "User   : goodbye. --> (Repaired as) Goodbye\n",
      "Bot    : Bye for now!\n"
     ]
    }
   ],
   "source": [
    "def converse():\n",
    "    intro_msg = \"Hello! I am Dumb Chatbot Mini or simply DCBM. Nice to meet you.\"\n",
    "    conversations = [intro_msg]\n",
    "    print(f\"Bot    : {intro_msg}\")\n",
    "    speak(intro_msg)\n",
    "\n",
    "    conversing = True\n",
    "    while conversing:\n",
    "        prompt = listen(timeout=30)\n",
    "        if not prompt:\n",
    "            continue\n",
    "        if re.match(r\"(?i)^(exit|quit|bye|goodbye|good bye|cancel|stop)\\b\", prompt):\n",
    "            conversing = False\n",
    "        prompt += \".\"\n",
    "        print(f\"User   : {prompt}\", end='')\n",
    "\n",
    "        context = f\"{\"\\n\".join(conversations[-10:])}\"\n",
    "        prompt = repair_prompt(context, prompt)\n",
    "        print(f\" --> (Repaired as) {prompt}\")\n",
    "\n",
    "        input = f\"\"\"\n",
    "            You are a helpful assistant named \"Dumb Chatbot Mini\" or \"DCBM\" or \"Bot\".\n",
    "            You will be given a conversation context and a user prompt. \n",
    "            Your task is to respond to the user prompt as \"Bot\" based on the context.\n",
    "            Keep your response short and concise, ideally one or two sentences.\n",
    "            Do not include any additional text or explanation in your response.\n",
    "            Do not repeat or include new user prompt in your response.\n",
    "            Do not add conversation context to your response.\n",
    "            Repond with an short good bye message if the user says any of the following: \"exit\", \"quit\", \"bye\", \"goodbye\", \"good bye\", \"cancel\", \"stop\".\n",
    "\n",
    "            Conversation context so far:\n",
    "            {context if context else \"No previous conversation context.\"}\n",
    "\n",
    "            User said: {prompt}\n",
    "            Bot said: \"\"\"\n",
    "\n",
    "        response = chat(model, torch.device(\"cuda\"), input, max_new_tokens=64, silent=True)\n",
    "        response = response[len(input):] if response.lower().startswith(input.lower()) else response        # remove context from response\n",
    "        response = response.replace(\"\\n\", \" \").strip()                                                      # replace newlines with spaces and strip leading/trailing spaces\n",
    "        response = re.sub(r\"(?i)Bot(:| said:?)\\s*\", \"\", response)                                           # replace \"Bot: \" or \"Bot said: \" with empty string\n",
    "        response = re.sub(r\"(?i)User(:| said:?).*$\", \"\", response)                                          # replace \"User: \" or \"User said: \" and everything after it with empty string\n",
    "        response = re.sub(r\"[0-9]+[.)>]\\s+\", \"\", response)                                                  # remove numbered lists like \"1) \", \"2) \", \"3) \", etc.\n",
    "        match = re.match(r'^(.*[.?!])[^.?!]*$', response)\n",
    "        response = match.group(1) if match else response                                                    # Remove incomplete sentences without ending punctuation\n",
    "\n",
    "        conversations += [f\"User said: {prompt}\", f\"Bot said: {response}\"]\n",
    "        print(f\"Bot    : {response}\")\n",
    "        speak(response)\n",
    "    return conversations\n",
    "\n",
    "conversations = converse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d05b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
